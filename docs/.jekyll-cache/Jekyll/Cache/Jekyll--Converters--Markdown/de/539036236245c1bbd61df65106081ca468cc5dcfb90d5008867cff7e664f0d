I"5<p><span class="tag  is-primary ">
    DeepLearning
</span></p>

<h1 id="apple-silicon에-pytorch-설치하기">Apple Silicon에 PyTorch 설치하기</h1>

<p>아마 2020년이었나… 애플 실리콘 아키텍쳐의 Macbook이 출시되었다.</p>

<p>나는 현재 M1 macbook pro를 쓰고있는데, 이전에는 anaconda도 안되서 mini-forge라는 걸 사용했었다.</p>

<p>그리고 그 mini-forge에는 말도 안되는 반쪽짜리 pytorch를 설치해서 사용했었다.</p>

<p>이 pytorch가 구동이 안되는 것은 아니다. 어찌어찌해서 설치해서 하면 뭔가 되긴했었는데 GPU 가속도 안되고 여러 제약사항이 있었다.
(물론 개발은 서버가 있기 때문에 딱히 상관은 없었는데… 가벼운 것이라도 잘 돌리고 싶긴 하니까?!)</p>

<p>하지만! 드디어</p>

<blockquote>
  <p>💡 <strong>Apple Silicon(M1) 을 위한 Anaconda 와 PyTorch가 정식 출시되었다!</strong></p>
</blockquote>

<ul>
  <li>Pytorch 관련 기사 : <a href="https://pytorch.org/blog/introducing-accelerated-pytorch-training-on-mac/?fbclid=IwAR25rWBO7pCnLzuOLNb2rRjQLP_oOgLZmkJUg2wvBdYqzL72S5nppjg9Rvc">Introducing Accelerated PyTorch Training on Mac</a></li>
</ul>

<p>아직 Preview 버전이라는거니까 정식(?)은 아닌걸로…</p>

<h2 id="1-anaconda-설치">1. Anaconda 설치</h2>

<p>Anaconda 설치는 매우 쉽다. Anaconda 공식 홈페이지에서 pkg 파일을 다운로드 하여 그냥 더블클릭하고 설치하면 된다.</p>

<ol>
  <li>
    <table>
      <tbody>
        <tr>
          <td><strong>Anaconda download page 를 들어간다.</strong> : [Anaconda</td>
          <td>Anaconda Distribution](https://www.anaconda.com/products/distribution)</td>
        </tr>
      </tbody>
    </table>
  </li>
  <li>
    <p><strong>사과 아이콘을 클릭한다. (맨 아래로 이동됨.)</strong>
<img src="https://velog.velcdn.com/images/bolero2/post/ee7a8a87-acfe-4614-8d50-5f070c35627f/image.png" alt="" /></p>
  </li>
  <li>
    <p><strong>맨 아래에서 64-Bit(M1) Graphical Installer (428MB) 를 클릭한다.</strong>
<img src="https://velog.velcdn.com/images/bolero2/post/0ef75259-038b-4a76-ae3e-51b78c344a8f/image.png" alt="" /></p>
  </li>
  <li><strong>그러면 아래처럼 pkg 파일이 다운로드 된다. (arm64=apple silicon 아키텍쳐임.)</strong>
<img src="https://velog.velcdn.com/images/bolero2/post/4dcbb047-29ca-4bc6-b7df-39c90a463d99/image.png" alt="" /></li>
</ol>

<p>pkg 파일이 다운로드가 완료되면, 아래처럼 뭔가 경고도 뜨고 계약서 동의도 하고, 디스크 지정도 해줘야 한다.</p>

<table>
  <thead>
    <tr>
      <th style="text-align: center">install-1</th>
      <th style="text-align: center">install-2</th>
      <th style="text-align: center">install-3</th>
      <th style="text-align: center">install-4</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: center"><img src="https://velog.velcdn.com/images/bolero2/post/c5a7da7a-26f5-428e-b020-42fdcf8481a3/image.png" alt="" /></td>
      <td style="text-align: center"><img src="https://velog.velcdn.com/images/bolero2/post/6530967f-749b-4628-93a7-964aae4eed79/image.png" alt="" /></td>
      <td style="text-align: center"><img src="https://velog.velcdn.com/images/bolero2/post/5b9e3851-29f4-45b7-8b9a-5ea2d2c76109/image.png" alt="" /></td>
      <td style="text-align: center"><img src="https://velog.velcdn.com/images/bolero2/post/3a568b29-7b45-4645-9e60-f37c5ba19c93/image.png" alt="" /></td>
    </tr>
  </tbody>
</table>

<p>그리고는 설치하면 된다…</p>

<ul>
  <li>세팅도 자동으로 해줘서 매~우 편하다.
<img src="https://velog.velcdn.com/images/bolero2/post/f6fd127e-f3a8-48b4-9ce3-400b74ad9b25/image.png" alt="" /></li>
</ul>

<blockquote>
  <p>Anaconda 가 잘 뜨는지 확인하자.
matplotlib 패키지가 잘 import 되는 걸 보니 Anaconda가 틀림없다…</p>
</blockquote>

<ul>
  <li>conda init 세팅은 <code class="language-plaintext highlighter-rouge">vi ~/.zshrc</code> 로 확인할 수 있다.
<img src="https://velog.velcdn.com/images/bolero2/post/fcd3c298-dfe6-48b6-b3e4-9c3a1c5624e2/image.png" alt="" /></li>
</ul>

<blockquote>
  <p>/Users/{username}/opt/anaconda3 에 실제 파일들이 들어있다.
삭제하고 싶으면 해당 폴더를 삭제해주자.</p>
</blockquote>

<h1 id="2-pytorch-설치">2. PyTorch 설치</h1>

<p>Anaconda m1 버전을 잘 설치했으니, PyTorch를 설치해주자.</p>

<p>PyTorch 설치는 정말 매우 쉽다.</p>

<p>우선, <a href="https://pytorch.org/get-started/locally/">https://pytorch.org/get-started/locally/</a> 로 가서 설치 커맨드를 알아야 한다.
<img src="https://velog.velcdn.com/images/bolero2/post/6003e2bf-22f6-4125-9494-41021b0e5bf7/image.png" alt="" /></p>

<p>(아까 공식 칼럼에서 보았듯이, Nightly 버전으로 설치해야 한다.)</p>

<p><code class="language-plaintext highlighter-rouge">pip install --pre torch torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/nightly/cpu </code></p>

<p>로 설치하면 된다. 바로 설치해보자.
<img src="https://velog.velcdn.com/images/bolero2/post/b13e16ec-d7de-4ad3-9ed4-733aac871746/image.png" alt="" /></p>

<p>PyTorch 설치도 끝났다.</p>

<h1 id="3-pytorch-in-m1---gpu-acceleration">3. PyTorch in M1 - GPU Acceleration</h1>

<p>일반적인 Nvidia gpu를 사용한다면 GPU 가속화를 위해 어떻게 해야 했을까.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">torch</span>

<span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">device</span><span class="p">(</span><span class="s">'cuda:0'</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">" - device : </span><span class="si">{</span><span class="n">device</span><span class="si">}</span><span class="s">"</span><span class="p">)</span>
<span class="n">sample</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">Tensor</span><span class="p">([[</span><span class="mi">10</span><span class="p">,</span> <span class="mi">20</span><span class="p">,</span> <span class="mi">30</span><span class="p">],</span> <span class="p">[</span><span class="mi">30</span><span class="p">,</span> <span class="mi">20</span><span class="p">,</span> <span class="mi">10</span><span class="p">]])</span>
<span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">" - cpu tensor : "</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">sample</span><span class="p">)</span>
<span class="n">sample</span> <span class="o">=</span> <span class="n">sample</span><span class="p">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">" - gpu tensor : "</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">sample</span><span class="p">)</span>
</code></pre></div></div>

<p>이렇게 하면 gpu 가속이 가능했다. (cuda:0번 gpu device에 tensor 할당)
<img src="https://velog.velcdn.com/images/bolero2/post/676b9471-2900-4f88-b2dd-2d399627ce8c/image.png" alt="" /></p>

<p>이렇게, gpu tensor 출력 부분의 <code class="language-plaintext highlighter-rouge">device</code> 쪽에 <strong><code class="language-plaintext highlighter-rouge">‘cuda:0’</code></strong>이 잘 들어간 것을 볼 수 있다.</p>

<p>그렇다면 M1은 어디에 할당해줘야 할까?</p>

<p>M1 의 경우에는, ‘cuda’ 말고 <strong>‘mps’</strong>에 할당해야 한다.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">torch</span>

<span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">device</span><span class="p">(</span><span class="s">'mps'</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">" - device : </span><span class="si">{</span><span class="n">device</span><span class="si">}</span><span class="s">"</span><span class="p">)</span>
<span class="n">sample</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">Tensor</span><span class="p">([[</span><span class="mi">10</span><span class="p">,</span> <span class="mi">20</span><span class="p">,</span> <span class="mi">30</span><span class="p">],</span> <span class="p">[</span><span class="mi">30</span><span class="p">,</span> <span class="mi">20</span><span class="p">,</span> <span class="mi">10</span><span class="p">]])</span>
<span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">" - cpu tensor : "</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">sample</span><span class="p">)</span>
<span class="n">sample</span> <span class="o">=</span> <span class="n">sample</span><span class="p">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">" - gpu tensor : "</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">sample</span><span class="p">)</span>
</code></pre></div></div>

<p>해당 스크립트를 실행하면
<img src="https://velog.velcdn.com/images/bolero2/post/7348052f-5f0b-478b-9fa3-b24dd9c9bbdd/image.png" alt="" /></p>

<p><code class="language-plaintext highlighter-rouge">device=</code> 쪽에 <code class="language-plaintext highlighter-rouge">‘cuda:0’</code> 이 아닌 <strong><code class="language-plaintext highlighter-rouge">‘mps’</code></strong> 가 들어가 있는 것을 확인할 수 있다.</p>

<h1 id="4-speed-comparison">4. Speed Comparison</h1>

<p>속도 비교를 해보자.</p>

<p>당연히 nvidia gpu보다는 느릴 것으로 예상이 되긴 하지만… 얼마나 차이가 날까?</p>

<p>비교 대상은 총 4종류이다.</p>

<table>
  <thead>
    <tr>
      <th style="text-align: left">Machine type</th>
      <th style="text-align: left">Name</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: left">Server GPU</td>
      <td style="text-align: left">Nvidia RTX A6000</td>
    </tr>
    <tr>
      <td style="text-align: left">M1 GPU</td>
      <td style="text-align: left">M1 GPU, 8 Core</td>
    </tr>
    <tr>
      <td style="text-align: left">Server CPU</td>
      <td style="text-align: left">Intel(R) Xeon(R) Silver 4210R CPU @ 2.40GHz * 40 Core</td>
    </tr>
    <tr>
      <td style="text-align: left">M1 CPU</td>
      <td style="text-align: left">M1 CPU</td>
    </tr>
  </tbody>
</table>

<p>간단하게 MNIST 데이터셋을 분류하는 torch 모델을 작성했다.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">time</span>
<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">datetime</span>
<span class="kn">import</span> <span class="nn">math</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">from</span> <span class="nn">torch.nn.functional</span> <span class="kn">import</span> <span class="n">softmax</span>
<span class="kn">from</span> <span class="nn">torch</span> <span class="kn">import</span> <span class="n">nn</span>
<span class="kn">from</span> <span class="nn">torch</span> <span class="kn">import</span> <span class="n">optim</span>
<span class="kn">import</span> <span class="nn">torchvision</span>
<span class="kn">import</span> <span class="nn">torchvision.transforms</span> <span class="k">as</span> <span class="n">transforms</span>

<span class="c1"># device setting, nvidia='cuda:0' | m1='mps' | cpu='cpu'
</span><span class="n">DEVICE</span> <span class="o">=</span> <span class="s">'cuda:0'</span>    <span class="c1"># "cuda:0" or "mps" or "cpu"
</span>
<span class="n">EPOCHS</span> <span class="o">=</span> <span class="mi">20</span>
<span class="n">BATCH_SIZE</span> <span class="o">=</span> <span class="mi">16</span> 
<span class="n">LEARNING_RATE</span> <span class="o">=</span> <span class="mf">0.0001</span>

<span class="k">class</span> <span class="nc">Model</span><span class="p">(</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">Model</span><span class="p">,</span> <span class="bp">self</span><span class="p">).</span><span class="n">__init__</span><span class="p">()</span>

        <span class="bp">self</span><span class="p">.</span><span class="n">num_classes</span> <span class="o">=</span> <span class="mi">10</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">ch</span> <span class="o">=</span> <span class="mi">1</span>

        <span class="bp">self</span><span class="p">.</span><span class="n">conv1</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">ch</span><span class="p">,</span> <span class="mi">128</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">bn1</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">BatchNorm2d</span><span class="p">(</span><span class="mi">128</span><span class="p">)</span>

        <span class="bp">self</span><span class="p">.</span><span class="n">conv2</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">bn2</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">BatchNorm2d</span><span class="p">(</span><span class="mi">256</span><span class="p">)</span>

        <span class="bp">self</span><span class="p">.</span><span class="n">actv</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">ReLU</span><span class="p">(</span><span class="n">inplace</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">maxpool</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">MaxPool2d</span><span class="p">(</span><span class="n">kernel_size</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">dropout</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">Dropout2d</span><span class="p">(</span><span class="n">p</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>

        <span class="bp">self</span><span class="p">.</span><span class="n">flatten</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">Flatten</span><span class="p">()</span>

        <span class="bp">self</span><span class="p">.</span><span class="n">fn1</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">7</span> <span class="o">*</span> <span class="mi">7</span> <span class="o">*</span> <span class="mi">256</span><span class="p">,</span> <span class="mi">256</span><span class="p">)</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">fn2</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">256</span><span class="p">,</span> <span class="mi">100</span><span class="p">)</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">fn3</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span> <span class="bp">self</span><span class="p">.</span><span class="n">num_classes</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">conv1</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">bn1</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">actv</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">maxpool</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">conv2</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">bn2</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">actv</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">maxpool</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">dropout</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">flatten</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">fn1</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">fn2</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">fn3</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">softmax</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

<span class="n">train_set</span> <span class="o">=</span> <span class="n">torchvision</span><span class="p">.</span><span class="n">datasets</span><span class="p">.</span><span class="n">MNIST</span><span class="p">(</span>
    <span class="n">root</span> <span class="o">=</span> <span class="s">'./data/MNIST'</span><span class="p">,</span>
    <span class="n">train</span> <span class="o">=</span> <span class="bp">True</span><span class="p">,</span>
    <span class="n">download</span> <span class="o">=</span> <span class="bp">True</span><span class="p">,</span>
    <span class="n">transform</span> <span class="o">=</span> <span class="n">transforms</span><span class="p">.</span><span class="n">Compose</span><span class="p">([</span>
        <span class="n">transforms</span><span class="p">.</span><span class="n">ToTensor</span><span class="p">()</span> <span class="c1"># 데이터를 0에서 255까지 있는 값을 0에서 1사이 값으로 변환
</span>    <span class="p">])</span>
<span class="p">)</span>

<span class="n">test_set</span> <span class="o">=</span> <span class="n">torchvision</span><span class="p">.</span><span class="n">datasets</span><span class="p">.</span><span class="n">MNIST</span><span class="p">(</span>
    <span class="n">root</span> <span class="o">=</span> <span class="s">'./data/MNIST'</span><span class="p">,</span>
    <span class="n">train</span> <span class="o">=</span> <span class="bp">False</span><span class="p">,</span>
    <span class="n">download</span> <span class="o">=</span> <span class="bp">True</span><span class="p">,</span>
    <span class="n">transform</span> <span class="o">=</span> <span class="n">transforms</span><span class="p">.</span><span class="n">Compose</span><span class="p">([</span>
        <span class="n">transforms</span><span class="p">.</span><span class="n">ToTensor</span><span class="p">()</span> <span class="c1"># 데이터를 0에서 255까지 있는 값을 0에서 1사이 값으로 변환
</span>    <span class="p">])</span>
<span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">Model</span><span class="p">()</span>
<span class="n">n_params</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="n">p</span><span class="p">.</span><span class="n">numel</span><span class="p">()</span> <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">model</span><span class="p">.</span><span class="n">parameters</span><span class="p">())</span>

<span class="k">print</span><span class="p">(</span><span class="s">"</span><span class="se">\n</span><span class="s">===== Model Architecture ====="</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="s">"</span><span class="se">\n</span><span class="s">"</span><span class="p">)</span>

<span class="k">print</span><span class="p">(</span><span class="s">"</span><span class="se">\n</span><span class="s">===== Model Parameters ====="</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">" - {}"</span><span class="p">.</span><span class="nb">format</span><span class="p">(</span><span class="n">n_params</span><span class="p">),</span> <span class="s">"</span><span class="se">\n\n</span><span class="s">"</span><span class="p">)</span>

<span class="n">train_loader</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">utils</span><span class="p">.</span><span class="n">data</span><span class="p">.</span><span class="n">DataLoader</span><span class="p">(</span><span class="n">train_set</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BATCH_SIZE</span><span class="p">)</span>
<span class="n">test_loader</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">utils</span><span class="p">.</span><span class="n">data</span><span class="p">.</span><span class="n">DataLoader</span><span class="p">(</span><span class="n">test_set</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BATCH_SIZE</span><span class="p">)</span>

<span class="n">total_train_iter</span> <span class="o">=</span> <span class="n">math</span><span class="p">.</span><span class="n">ceil</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">train_set</span><span class="p">)</span> <span class="o">/</span> <span class="n">BATCH_SIZE</span><span class="p">)</span>
<span class="n">total_valid_iter</span> <span class="o">=</span> <span class="n">math</span><span class="p">.</span><span class="n">ceil</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">test_set</span><span class="p">)</span> <span class="o">/</span> <span class="n">BATCH_SIZE</span><span class="p">)</span>

<span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">device</span><span class="p">(</span><span class="n">DEVICE</span><span class="p">)</span>
<span class="n">criterion</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">CrossEntropyLoss</span><span class="p">().</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">optim</span><span class="p">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">model</span><span class="p">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="n">LEARNING_RATE</span><span class="p">)</span>

<span class="n">model</span><span class="p">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

<span class="n">train_start</span> <span class="o">=</span> <span class="n">time</span><span class="p">.</span><span class="n">time</span><span class="p">()</span>
<span class="n">epochs_times</span> <span class="o">=</span> <span class="p">[]</span>

<span class="k">print</span><span class="p">(</span><span class="s">"</span><span class="se">\n\n</span><span class="s">Training start time : {}</span><span class="se">\n\n</span><span class="s">"</span><span class="p">.</span><span class="nb">format</span><span class="p">(</span><span class="n">datetime</span><span class="p">.</span><span class="n">datetime</span><span class="p">.</span><span class="n">now</span><span class="p">()))</span>

<span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">EPOCHS</span><span class="p">):</span>
    <span class="n">epoch_start</span> <span class="o">=</span> <span class="n">time</span><span class="p">.</span><span class="n">time</span><span class="p">()</span>
    <span class="n">train_loss</span><span class="p">,</span> <span class="n">train_acc</span> <span class="o">=</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.0</span>

    <span class="k">for</span> <span class="n">step</span><span class="p">,</span> <span class="n">data</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">train_loader</span><span class="p">):</span>
        <span class="n">iter_start</span> <span class="o">=</span> <span class="n">time</span><span class="p">.</span><span class="n">time</span><span class="p">()</span>
        <span class="n">model</span><span class="p">.</span><span class="n">train</span><span class="p">()</span>
        <span class="n">image</span><span class="p">,</span> <span class="n">target</span> <span class="o">=</span> <span class="n">data</span>

        <span class="n">image</span>  <span class="o">=</span> <span class="n">image</span><span class="p">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
        <span class="n">target</span> <span class="o">=</span> <span class="n">target</span><span class="p">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

        <span class="n">out</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">image</span><span class="p">)</span>

        <span class="n">acc</span> <span class="o">=</span> <span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="nb">max</span><span class="p">(</span><span class="n">out</span><span class="p">,</span> <span class="mi">1</span><span class="p">)[</span><span class="mi">1</span><span class="p">].</span><span class="n">cpu</span><span class="p">().</span><span class="n">numpy</span><span class="p">()</span> <span class="o">==</span> <span class="n">target</span><span class="p">.</span><span class="n">cpu</span><span class="p">().</span><span class="n">numpy</span><span class="p">())</span>
        <span class="n">acc</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">count_nonzero</span><span class="p">(</span><span class="n">acc</span><span class="p">)</span> <span class="o">/</span> <span class="n">BATCH_SIZE</span><span class="p">)</span>

        <span class="n">loss</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">(</span><span class="n">out</span><span class="p">,</span> <span class="n">target</span><span class="p">)</span>
        <span class="n">optimizer</span><span class="p">.</span><span class="n">zero_grad</span><span class="p">()</span>
        <span class="n">loss</span><span class="p">.</span><span class="n">backward</span><span class="p">()</span>
        <span class="n">optimizer</span><span class="p">.</span><span class="n">step</span><span class="p">()</span>

        <span class="n">train_loss</span> <span class="o">+=</span> <span class="n">loss</span><span class="p">.</span><span class="n">item</span><span class="p">()</span>
        <span class="n">train_acc</span> <span class="o">+=</span> <span class="n">acc</span>

        <span class="k">if</span> <span class="n">step</span> <span class="o">%</span> <span class="nb">int</span><span class="p">(</span><span class="n">total_train_iter</span> <span class="o">/</span> <span class="mi">2</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">print</span><span class="p">(</span><span class="s">"[train %5s/%5s] Epoch: %4s | Time: %6.2fs | loss: %10.4f | Acc: %10.4f"</span> <span class="o">%</span> <span class="p">(</span>
                            <span class="n">step</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">total_train_iter</span><span class="p">,</span> <span class="n">epoch</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">time</span><span class="p">.</span><span class="n">time</span><span class="p">()</span> <span class="o">-</span> <span class="n">iter_start</span><span class="p">,</span> <span class="nb">round</span><span class="p">(</span><span class="n">loss</span><span class="p">.</span><span class="n">item</span><span class="p">(),</span> <span class="mi">4</span><span class="p">),</span> <span class="nb">float</span><span class="p">(</span><span class="n">acc</span><span class="p">)))</span>

    <span class="n">train_loss</span> <span class="o">=</span> <span class="n">train_loss</span> <span class="o">/</span> <span class="n">total_train_iter</span>
    <span class="n">train_acc</span> <span class="o">=</span> <span class="n">train_acc</span> <span class="o">/</span> <span class="n">total_train_iter</span>
    <span class="n">epoch_runtime</span> <span class="o">=</span> <span class="n">time</span><span class="p">.</span><span class="n">time</span><span class="p">()</span> <span class="o">-</span> <span class="n">epoch_start</span>
    <span class="k">print</span><span class="p">(</span><span class="s">"[Epoch {} training Ended] &gt; Time: {:.2}s/epoch | Loss: {:.4f} | Acc: {:g}</span><span class="se">\n</span><span class="s">"</span><span class="p">.</span><span class="nb">format</span><span class="p">(</span>
        <span class="n">epoch</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">epoch_runtime</span><span class="p">,</span> <span class="n">np</span><span class="p">.</span><span class="n">mean</span><span class="p">(</span><span class="n">train_loss</span><span class="p">),</span> <span class="n">train_acc</span><span class="p">))</span>
    
    <span class="n">epochs_times</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">epoch_runtime</span><span class="p">)</span>

<span class="n">program_runtime</span> <span class="o">=</span> <span class="n">time</span><span class="p">.</span><span class="n">time</span><span class="p">()</span> <span class="o">-</span> <span class="n">train_start</span>

<span class="k">print</span><span class="p">(</span><span class="s">"</span><span class="se">\n\n</span><span class="s">Training running time : {:.2}</span><span class="se">\n\n</span><span class="s">"</span><span class="p">.</span><span class="nb">format</span><span class="p">(</span><span class="n">program_runtime</span><span class="p">))</span>

<span class="n">epochs_times</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">map</span><span class="p">(</span><span class="nb">str</span><span class="p">,</span> <span class="n">epochs_times</span><span class="p">))</span>
<span class="n">epochs_times</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="nb">str</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="o">+</span> <span class="s">"</span><span class="se">\n</span><span class="s">"</span><span class="p">,</span> <span class="n">epochs_times</span><span class="p">))</span>

<span class="n">filename</span> <span class="o">=</span> <span class="n">os</span><span class="p">.</span><span class="n">path</span><span class="p">.</span><span class="n">basename</span><span class="p">(</span><span class="n">__file__</span><span class="p">).</span><span class="n">split</span><span class="p">(</span><span class="s">'.'</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="s">".txt"</span>
<span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">filename</span><span class="p">,</span> <span class="s">'w'</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
    <span class="n">f</span><span class="p">.</span><span class="n">writelines</span><span class="p">(</span><span class="n">epochs_times</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">'save success epoch times! -&gt; </span><span class="si">{</span><span class="n">filename</span><span class="si">}</span><span class="s">'</span><span class="p">)</span>
</code></pre></div></div>

<p>실험하다보니 엄청난 뭔가가 있었다…</p>

<blockquote>
  <p>🧐 실험하면서 포스팅 작성 중인데, m1에서 image size=224 로 하고 batch_size=64로 설정 후에 학습을 실행하면 쓰로틀링이 걸린다!!! 이게 맞나??</p>

  <p>아직 대규모의 학습은 제대로 잘 안되는 느낌이다…</p>
</blockquote>

<ul>
  <li><strong>1 Epoch 경과 시간 (M1 GPU vs Server GPU)</strong></li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">(</span>base<span class="o">)</span> bolero is <span class="k">in </span>now ~ <span class="nv">$ </span>python m1_gpu.py 

<span class="o">=====</span> Model Architecture <span class="o">=====</span>
Model<span class="o">(</span>
  <span class="o">(</span>conv1<span class="o">)</span>: Conv2d<span class="o">(</span>1, 128, <span class="nv">kernel_size</span><span class="o">=(</span>3, 3<span class="o">)</span>, <span class="nv">stride</span><span class="o">=(</span>1, 1<span class="o">)</span>, <span class="nv">padding</span><span class="o">=(</span>1, 1<span class="o">))</span>
  <span class="o">(</span>bn1<span class="o">)</span>: BatchNorm2d<span class="o">(</span>128, <span class="nv">eps</span><span class="o">=</span>1e-05, <span class="nv">momentum</span><span class="o">=</span>0.1, <span class="nv">affine</span><span class="o">=</span>True, <span class="nv">track_running_stats</span><span class="o">=</span>True<span class="o">)</span>
  <span class="o">(</span>conv2<span class="o">)</span>: Conv2d<span class="o">(</span>128, 256, <span class="nv">kernel_size</span><span class="o">=(</span>3, 3<span class="o">)</span>, <span class="nv">stride</span><span class="o">=(</span>1, 1<span class="o">)</span>, <span class="nv">padding</span><span class="o">=(</span>1, 1<span class="o">))</span>
  <span class="o">(</span>bn2<span class="o">)</span>: BatchNorm2d<span class="o">(</span>256, <span class="nv">eps</span><span class="o">=</span>1e-05, <span class="nv">momentum</span><span class="o">=</span>0.1, <span class="nv">affine</span><span class="o">=</span>True, <span class="nv">track_running_stats</span><span class="o">=</span>True<span class="o">)</span>
  <span class="o">(</span>actv<span class="o">)</span>: ReLU<span class="o">(</span><span class="nv">inplace</span><span class="o">=</span>True<span class="o">)</span>
  <span class="o">(</span>maxpool<span class="o">)</span>: MaxPool2d<span class="o">(</span><span class="nv">kernel_size</span><span class="o">=</span>2, <span class="nv">stride</span><span class="o">=</span>2, <span class="nv">padding</span><span class="o">=</span>0, <span class="nv">dilation</span><span class="o">=</span>1, <span class="nv">ceil_mode</span><span class="o">=</span>False<span class="o">)</span>
  <span class="o">(</span>dropout<span class="o">)</span>: Dropout2d<span class="o">(</span><span class="nv">p</span><span class="o">=</span>0.5, <span class="nv">inplace</span><span class="o">=</span>False<span class="o">)</span>
  <span class="o">(</span>flatten<span class="o">)</span>: Flatten<span class="o">(</span><span class="nv">start_dim</span><span class="o">=</span>1, <span class="nv">end_dim</span><span class="o">=</span><span class="nt">-1</span><span class="o">)</span>
  <span class="o">(</span>fn1<span class="o">)</span>: Linear<span class="o">(</span><span class="nv">in_features</span><span class="o">=</span>12544, <span class="nv">out_features</span><span class="o">=</span>256, <span class="nv">bias</span><span class="o">=</span>True<span class="o">)</span>
  <span class="o">(</span>fn2<span class="o">)</span>: Linear<span class="o">(</span><span class="nv">in_features</span><span class="o">=</span>256, <span class="nv">out_features</span><span class="o">=</span>100, <span class="nv">bias</span><span class="o">=</span>True<span class="o">)</span>
  <span class="o">(</span>fn3<span class="o">)</span>: Linear<span class="o">(</span><span class="nv">in_features</span><span class="o">=</span>100, <span class="nv">out_features</span><span class="o">=</span>10, <span class="nv">bias</span><span class="o">=</span>True<span class="o">)</span>
<span class="o">)</span> 

<span class="o">=====</span> Model Parameters <span class="o">=====</span>
 - 3535446 

Training start <span class="nb">time</span> : 2022-06-01 12:36:36.501451

/Users/bolero/m1_gpu.py:63: UserWarning: Implicit dimension choice <span class="k">for </span>softmax has been deprecated. Change the call to include <span class="nv">dim</span><span class="o">=</span>X as an argument.
  <span class="k">return </span>softmax<span class="o">(</span>x<span class="o">)</span>
<span class="o">[</span>train     1/ 3750] Epoch:    1 | Time:   0.32s | loss:     2.3119 | Acc:     0.1250
<span class="o">[</span>train  1876/ 3750] Epoch:    1 | Time:   0.03s | loss:     1.4933 | Acc:     0.9375
<span class="o">[</span>Epoch 1 training Ended] <span class="o">&gt;</span> Time: 1.3e+02s/epoch | Loss: 1.5247 | Acc: 0.9397
</code></pre></div></div>

<p><strong><em>M1 Macbook Pro</em></strong></p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">(</span>neural<span class="o">)</span> NvidiaServer@NvidiaServer:~<span class="nv">$ </span>python server_gpu.py 

<span class="o">=====</span> Model Architecture <span class="o">=====</span>
Model<span class="o">(</span>
  <span class="o">(</span>conv1<span class="o">)</span>: Conv2d<span class="o">(</span>1, 128, <span class="nv">kernel_size</span><span class="o">=(</span>3, 3<span class="o">)</span>, <span class="nv">stride</span><span class="o">=(</span>1, 1<span class="o">)</span>, <span class="nv">padding</span><span class="o">=(</span>1, 1<span class="o">))</span>
  <span class="o">(</span>bn1<span class="o">)</span>: BatchNorm2d<span class="o">(</span>128, <span class="nv">eps</span><span class="o">=</span>1e-05, <span class="nv">momentum</span><span class="o">=</span>0.1, <span class="nv">affine</span><span class="o">=</span>True, <span class="nv">track_running_stats</span><span class="o">=</span>True<span class="o">)</span>
  <span class="o">(</span>conv2<span class="o">)</span>: Conv2d<span class="o">(</span>128, 256, <span class="nv">kernel_size</span><span class="o">=(</span>3, 3<span class="o">)</span>, <span class="nv">stride</span><span class="o">=(</span>1, 1<span class="o">)</span>, <span class="nv">padding</span><span class="o">=(</span>1, 1<span class="o">))</span>
  <span class="o">(</span>bn2<span class="o">)</span>: BatchNorm2d<span class="o">(</span>256, <span class="nv">eps</span><span class="o">=</span>1e-05, <span class="nv">momentum</span><span class="o">=</span>0.1, <span class="nv">affine</span><span class="o">=</span>True, <span class="nv">track_running_stats</span><span class="o">=</span>True<span class="o">)</span>
  <span class="o">(</span>actv<span class="o">)</span>: ReLU<span class="o">(</span><span class="nv">inplace</span><span class="o">=</span>True<span class="o">)</span>
  <span class="o">(</span>maxpool<span class="o">)</span>: MaxPool2d<span class="o">(</span><span class="nv">kernel_size</span><span class="o">=</span>2, <span class="nv">stride</span><span class="o">=</span>2, <span class="nv">padding</span><span class="o">=</span>0, <span class="nv">dilation</span><span class="o">=</span>1, <span class="nv">ceil_mode</span><span class="o">=</span>False<span class="o">)</span>
  <span class="o">(</span>dropout<span class="o">)</span>: Dropout2d<span class="o">(</span><span class="nv">p</span><span class="o">=</span>0.5, <span class="nv">inplace</span><span class="o">=</span>False<span class="o">)</span>
  <span class="o">(</span>flatten<span class="o">)</span>: Flatten<span class="o">(</span><span class="nv">start_dim</span><span class="o">=</span>1, <span class="nv">end_dim</span><span class="o">=</span><span class="nt">-1</span><span class="o">)</span>
  <span class="o">(</span>fn1<span class="o">)</span>: Linear<span class="o">(</span><span class="nv">in_features</span><span class="o">=</span>12544, <span class="nv">out_features</span><span class="o">=</span>256, <span class="nv">bias</span><span class="o">=</span>True<span class="o">)</span>
  <span class="o">(</span>fn2<span class="o">)</span>: Linear<span class="o">(</span><span class="nv">in_features</span><span class="o">=</span>256, <span class="nv">out_features</span><span class="o">=</span>100, <span class="nv">bias</span><span class="o">=</span>True<span class="o">)</span>
  <span class="o">(</span>fn3<span class="o">)</span>: Linear<span class="o">(</span><span class="nv">in_features</span><span class="o">=</span>100, <span class="nv">out_features</span><span class="o">=</span>10, <span class="nv">bias</span><span class="o">=</span>True<span class="o">)</span>
<span class="o">)</span> 

<span class="o">=====</span> Model Parameters <span class="o">=====</span>
 - 3535446 

Training start <span class="nb">time</span> : 2022-06-01 03:36:49.959508

server_gpu.py:63: UserWarning: Implicit dimension choice <span class="k">for </span>softmax has been deprecated. Change the call to include <span class="nv">dim</span><span class="o">=</span>X as an argument.
  <span class="k">return </span>softmax<span class="o">(</span>x<span class="o">)</span>
<span class="o">[</span>train     1/ 3750] Epoch:    1 | Time:   0.04s | loss:     2.3063 | Acc:     0.0000
<span class="o">[</span>train  1876/ 3750] Epoch:    1 | Time:   0.01s | loss:     1.4613 | Acc:     1.0000
<span class="o">[</span>Epoch 1 training Ended] <span class="o">&gt;</span> Time: 2.7e+01s/epoch | Loss: 1.5264 | Acc: 0.938167
</code></pre></div></div>

<p><strong><em>Nvidia RTX A6000</em></strong></p>

<blockquote>
  <p>🧐 1 Epoch 까지만 봤을 때, Nvidia gpu 서버용<strong>(RTX A6000)</strong> 에서는 27초~28초/epoch가 걸렸고, <strong><em>m1 에서는 130초~140초/epoch가 걸렸다.</em>
약 5배정도 차이나는데</strong>, 현재 서버용 GPU 가 너무 우월한 점도 있다.</p>
</blockquote>

<ul>
  <li><strong>1 Epoch 경과 시간 (M1 GPU vs Server CPU)</strong></li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">(</span>base<span class="o">)</span> bolero is <span class="k">in </span>now ~ <span class="nv">$ </span>python m1_gpu.py 

<span class="o">=====</span> Model Architecture <span class="o">=====</span>
Model<span class="o">(</span>
  <span class="o">(</span>conv1<span class="o">)</span>: Conv2d<span class="o">(</span>1, 128, <span class="nv">kernel_size</span><span class="o">=(</span>3, 3<span class="o">)</span>, <span class="nv">stride</span><span class="o">=(</span>1, 1<span class="o">)</span>, <span class="nv">padding</span><span class="o">=(</span>1, 1<span class="o">))</span>
  <span class="o">(</span>bn1<span class="o">)</span>: BatchNorm2d<span class="o">(</span>128, <span class="nv">eps</span><span class="o">=</span>1e-05, <span class="nv">momentum</span><span class="o">=</span>0.1, <span class="nv">affine</span><span class="o">=</span>True, <span class="nv">track_running_stats</span><span class="o">=</span>True<span class="o">)</span>
  <span class="o">(</span>conv2<span class="o">)</span>: Conv2d<span class="o">(</span>128, 256, <span class="nv">kernel_size</span><span class="o">=(</span>3, 3<span class="o">)</span>, <span class="nv">stride</span><span class="o">=(</span>1, 1<span class="o">)</span>, <span class="nv">padding</span><span class="o">=(</span>1, 1<span class="o">))</span>
  <span class="o">(</span>bn2<span class="o">)</span>: BatchNorm2d<span class="o">(</span>256, <span class="nv">eps</span><span class="o">=</span>1e-05, <span class="nv">momentum</span><span class="o">=</span>0.1, <span class="nv">affine</span><span class="o">=</span>True, <span class="nv">track_running_stats</span><span class="o">=</span>True<span class="o">)</span>
  <span class="o">(</span>actv<span class="o">)</span>: ReLU<span class="o">(</span><span class="nv">inplace</span><span class="o">=</span>True<span class="o">)</span>
  <span class="o">(</span>maxpool<span class="o">)</span>: MaxPool2d<span class="o">(</span><span class="nv">kernel_size</span><span class="o">=</span>2, <span class="nv">stride</span><span class="o">=</span>2, <span class="nv">padding</span><span class="o">=</span>0, <span class="nv">dilation</span><span class="o">=</span>1, <span class="nv">ceil_mode</span><span class="o">=</span>False<span class="o">)</span>
  <span class="o">(</span>dropout<span class="o">)</span>: Dropout2d<span class="o">(</span><span class="nv">p</span><span class="o">=</span>0.5, <span class="nv">inplace</span><span class="o">=</span>False<span class="o">)</span>
  <span class="o">(</span>flatten<span class="o">)</span>: Flatten<span class="o">(</span><span class="nv">start_dim</span><span class="o">=</span>1, <span class="nv">end_dim</span><span class="o">=</span><span class="nt">-1</span><span class="o">)</span>
  <span class="o">(</span>fn1<span class="o">)</span>: Linear<span class="o">(</span><span class="nv">in_features</span><span class="o">=</span>12544, <span class="nv">out_features</span><span class="o">=</span>256, <span class="nv">bias</span><span class="o">=</span>True<span class="o">)</span>
  <span class="o">(</span>fn2<span class="o">)</span>: Linear<span class="o">(</span><span class="nv">in_features</span><span class="o">=</span>256, <span class="nv">out_features</span><span class="o">=</span>100, <span class="nv">bias</span><span class="o">=</span>True<span class="o">)</span>
  <span class="o">(</span>fn3<span class="o">)</span>: Linear<span class="o">(</span><span class="nv">in_features</span><span class="o">=</span>100, <span class="nv">out_features</span><span class="o">=</span>10, <span class="nv">bias</span><span class="o">=</span>True<span class="o">)</span>
<span class="o">)</span> 

<span class="o">=====</span> Model Parameters <span class="o">=====</span>
 - 3535446 

Training start <span class="nb">time</span> : 2022-06-01 12:36:36.501451

/Users/bolero/m1_gpu.py:63: UserWarning: Implicit dimension choice <span class="k">for </span>softmax has been deprecated. Change the call to include <span class="nv">dim</span><span class="o">=</span>X as an argument.
  <span class="k">return </span>softmax<span class="o">(</span>x<span class="o">)</span>
<span class="o">[</span>train     1/ 3750] Epoch:    1 | Time:   0.32s | loss:     2.3119 | Acc:     0.1250
<span class="o">[</span>train  1876/ 3750] Epoch:    1 | Time:   0.03s | loss:     1.4933 | Acc:     0.9375
<span class="o">[</span>Epoch 1 training Ended] <span class="o">&gt;</span> Time: 1.3e+02s/epoch | Loss: 1.5247 | Acc: 0.9397
</code></pre></div></div>

<p><strong><em>M1 Macbook Pro</em></strong></p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">(</span>neural<span class="o">)</span> NvidiaServer@NvidiaServer:~<span class="nv">$ </span>python server_cpu.py 

<span class="o">=====</span> Model Architecture <span class="o">=====</span>
Model<span class="o">(</span>
  <span class="o">(</span>conv1<span class="o">)</span>: Conv2d<span class="o">(</span>1, 128, <span class="nv">kernel_size</span><span class="o">=(</span>3, 3<span class="o">)</span>, <span class="nv">stride</span><span class="o">=(</span>1, 1<span class="o">)</span>, <span class="nv">padding</span><span class="o">=(</span>1, 1<span class="o">))</span>
  <span class="o">(</span>bn1<span class="o">)</span>: BatchNorm2d<span class="o">(</span>128, <span class="nv">eps</span><span class="o">=</span>1e-05, <span class="nv">momentum</span><span class="o">=</span>0.1, <span class="nv">affine</span><span class="o">=</span>True, <span class="nv">track_running_stats</span><span class="o">=</span>True<span class="o">)</span>
  <span class="o">(</span>conv2<span class="o">)</span>: Conv2d<span class="o">(</span>128, 256, <span class="nv">kernel_size</span><span class="o">=(</span>3, 3<span class="o">)</span>, <span class="nv">stride</span><span class="o">=(</span>1, 1<span class="o">)</span>, <span class="nv">padding</span><span class="o">=(</span>1, 1<span class="o">))</span>
  <span class="o">(</span>bn2<span class="o">)</span>: BatchNorm2d<span class="o">(</span>256, <span class="nv">eps</span><span class="o">=</span>1e-05, <span class="nv">momentum</span><span class="o">=</span>0.1, <span class="nv">affine</span><span class="o">=</span>True, <span class="nv">track_running_stats</span><span class="o">=</span>True<span class="o">)</span>
  <span class="o">(</span>actv<span class="o">)</span>: ReLU<span class="o">(</span><span class="nv">inplace</span><span class="o">=</span>True<span class="o">)</span>
  <span class="o">(</span>maxpool<span class="o">)</span>: MaxPool2d<span class="o">(</span><span class="nv">kernel_size</span><span class="o">=</span>2, <span class="nv">stride</span><span class="o">=</span>2, <span class="nv">padding</span><span class="o">=</span>0, <span class="nv">dilation</span><span class="o">=</span>1, <span class="nv">ceil_mode</span><span class="o">=</span>False<span class="o">)</span>
  <span class="o">(</span>dropout<span class="o">)</span>: Dropout2d<span class="o">(</span><span class="nv">p</span><span class="o">=</span>0.5, <span class="nv">inplace</span><span class="o">=</span>False<span class="o">)</span>
  <span class="o">(</span>flatten<span class="o">)</span>: Flatten<span class="o">(</span><span class="nv">start_dim</span><span class="o">=</span>1, <span class="nv">end_dim</span><span class="o">=</span><span class="nt">-1</span><span class="o">)</span>
  <span class="o">(</span>fn1<span class="o">)</span>: Linear<span class="o">(</span><span class="nv">in_features</span><span class="o">=</span>12544, <span class="nv">out_features</span><span class="o">=</span>256, <span class="nv">bias</span><span class="o">=</span>True<span class="o">)</span>
  <span class="o">(</span>fn2<span class="o">)</span>: Linear<span class="o">(</span><span class="nv">in_features</span><span class="o">=</span>256, <span class="nv">out_features</span><span class="o">=</span>100, <span class="nv">bias</span><span class="o">=</span>True<span class="o">)</span>
  <span class="o">(</span>fn3<span class="o">)</span>: Linear<span class="o">(</span><span class="nv">in_features</span><span class="o">=</span>100, <span class="nv">out_features</span><span class="o">=</span>10, <span class="nv">bias</span><span class="o">=</span>True<span class="o">)</span>
<span class="o">)</span> 

<span class="o">=====</span> Model Parameters <span class="o">=====</span>
 - 3535446 

Training start <span class="nb">time</span> : 2022-06-01 03:37:22.395249

server_cpu.py:63: UserWarning: Implicit dimension choice <span class="k">for </span>softmax has been deprecated. Change the call to include <span class="nv">dim</span><span class="o">=</span>X as an argument.
  <span class="k">return </span>softmax<span class="o">(</span>x<span class="o">)</span>
<span class="o">[</span>train     1/ 3750] Epoch:    1 | Time:   1.38s | loss:     2.3021 | Acc:     0.0625
<span class="o">[</span>train  1876/ 3750] Epoch:    1 | Time:   0.04s | loss:     1.4617 | Acc:     1.0000
<span class="o">[</span>Epoch 1 training Ended] <span class="o">&gt;</span> Time: 1.8e+02s/epoch | Loss: 1.5256 | Acc: 0.939617
</code></pre></div></div>

<p><strong><em>Intel(R) Xeon(R) Silver 4210R CPU @ 2.40GHz * 40 Core</em></strong></p>

<blockquote>
  <p>🧐 다행스럽게도(?) <strong>M1 GPU가 Server의 40 Core CPU보다는 빨랐다.</strong>
수치로 보자면 M1 GPU가 130초/epoch 정도 나오고, 40 Core CPU가 180초/epoch 정도 나온다. (<strong>약 1.4배정도 M1 GPU가 더 빠름</strong>)</p>
</blockquote>

<ol>
  <li><strong>1 Epoch 경과 시간 (M1 CPU vs M1 GPU)</strong></li>
</ol>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">(</span>base<span class="o">)</span> bolero is <span class="k">in </span>now ~ <span class="nv">$ </span>python m1_cpu.py 

<span class="o">=====</span> Model Architecture <span class="o">=====</span>
Model<span class="o">(</span>
  <span class="o">(</span>conv1<span class="o">)</span>: Conv2d<span class="o">(</span>1, 128, <span class="nv">kernel_size</span><span class="o">=(</span>3, 3<span class="o">)</span>, <span class="nv">stride</span><span class="o">=(</span>1, 1<span class="o">)</span>, <span class="nv">padding</span><span class="o">=(</span>1, 1<span class="o">))</span>
  <span class="o">(</span>bn1<span class="o">)</span>: BatchNorm2d<span class="o">(</span>128, <span class="nv">eps</span><span class="o">=</span>1e-05, <span class="nv">momentum</span><span class="o">=</span>0.1, <span class="nv">affine</span><span class="o">=</span>True, <span class="nv">track_running_stats</span><span class="o">=</span>True<span class="o">)</span>
  <span class="o">(</span>conv2<span class="o">)</span>: Conv2d<span class="o">(</span>128, 256, <span class="nv">kernel_size</span><span class="o">=(</span>3, 3<span class="o">)</span>, <span class="nv">stride</span><span class="o">=(</span>1, 1<span class="o">)</span>, <span class="nv">padding</span><span class="o">=(</span>1, 1<span class="o">))</span>
  <span class="o">(</span>bn2<span class="o">)</span>: BatchNorm2d<span class="o">(</span>256, <span class="nv">eps</span><span class="o">=</span>1e-05, <span class="nv">momentum</span><span class="o">=</span>0.1, <span class="nv">affine</span><span class="o">=</span>True, <span class="nv">track_running_stats</span><span class="o">=</span>True<span class="o">)</span>
  <span class="o">(</span>actv<span class="o">)</span>: ReLU<span class="o">(</span><span class="nv">inplace</span><span class="o">=</span>True<span class="o">)</span>
  <span class="o">(</span>maxpool<span class="o">)</span>: MaxPool2d<span class="o">(</span><span class="nv">kernel_size</span><span class="o">=</span>2, <span class="nv">stride</span><span class="o">=</span>2, <span class="nv">padding</span><span class="o">=</span>0, <span class="nv">dilation</span><span class="o">=</span>1, <span class="nv">ceil_mode</span><span class="o">=</span>False<span class="o">)</span>
  <span class="o">(</span>dropout<span class="o">)</span>: Dropout2d<span class="o">(</span><span class="nv">p</span><span class="o">=</span>0.5, <span class="nv">inplace</span><span class="o">=</span>False<span class="o">)</span>
  <span class="o">(</span>flatten<span class="o">)</span>: Flatten<span class="o">(</span><span class="nv">start_dim</span><span class="o">=</span>1, <span class="nv">end_dim</span><span class="o">=</span><span class="nt">-1</span><span class="o">)</span>
  <span class="o">(</span>fn1<span class="o">)</span>: Linear<span class="o">(</span><span class="nv">in_features</span><span class="o">=</span>12544, <span class="nv">out_features</span><span class="o">=</span>256, <span class="nv">bias</span><span class="o">=</span>True<span class="o">)</span>
  <span class="o">(</span>fn2<span class="o">)</span>: Linear<span class="o">(</span><span class="nv">in_features</span><span class="o">=</span>256, <span class="nv">out_features</span><span class="o">=</span>100, <span class="nv">bias</span><span class="o">=</span>True<span class="o">)</span>
  <span class="o">(</span>fn3<span class="o">)</span>: Linear<span class="o">(</span><span class="nv">in_features</span><span class="o">=</span>100, <span class="nv">out_features</span><span class="o">=</span>10, <span class="nv">bias</span><span class="o">=</span>True<span class="o">)</span>
<span class="o">)</span> 

<span class="o">=====</span> Model Parameters <span class="o">=====</span>
 - 3535446 

Training start <span class="nb">time</span> : 2022-06-01 12:36:37.141268

/Users/bolero/m1_cpu.py:63: UserWarning: Implicit dimension choice <span class="k">for </span>softmax has been deprecated. Change the call to include <span class="nv">dim</span><span class="o">=</span>X as an argument.
  <span class="k">return </span>softmax<span class="o">(</span>x<span class="o">)</span>
<span class="o">[</span>train     1/ 3750] Epoch:    1 | Time:   0.09s | loss:     2.3023 | Acc:     0.1250
<span class="o">[</span>train  1876/ 3750] Epoch:    1 | Time:   0.05s | loss:     1.4612 | Acc:     1.0000
<span class="o">[</span>Epoch 1 training Ended] <span class="o">&gt;</span> Time: 1.7e+02s/epoch | Loss: 1.5262 | Acc: 0.938867
</code></pre></div></div>

<p><strong><em>M1 Macbook Pro - CPU</em></strong></p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">(</span>base<span class="o">)</span> bolero is <span class="k">in </span>now ~ <span class="nv">$ </span>python m1_gpu.py 

<span class="o">=====</span> Model Architecture <span class="o">=====</span>
Model<span class="o">(</span>
  <span class="o">(</span>conv1<span class="o">)</span>: Conv2d<span class="o">(</span>1, 128, <span class="nv">kernel_size</span><span class="o">=(</span>3, 3<span class="o">)</span>, <span class="nv">stride</span><span class="o">=(</span>1, 1<span class="o">)</span>, <span class="nv">padding</span><span class="o">=(</span>1, 1<span class="o">))</span>
  <span class="o">(</span>bn1<span class="o">)</span>: BatchNorm2d<span class="o">(</span>128, <span class="nv">eps</span><span class="o">=</span>1e-05, <span class="nv">momentum</span><span class="o">=</span>0.1, <span class="nv">affine</span><span class="o">=</span>True, <span class="nv">track_running_stats</span><span class="o">=</span>True<span class="o">)</span>
  <span class="o">(</span>conv2<span class="o">)</span>: Conv2d<span class="o">(</span>128, 256, <span class="nv">kernel_size</span><span class="o">=(</span>3, 3<span class="o">)</span>, <span class="nv">stride</span><span class="o">=(</span>1, 1<span class="o">)</span>, <span class="nv">padding</span><span class="o">=(</span>1, 1<span class="o">))</span>
  <span class="o">(</span>bn2<span class="o">)</span>: BatchNorm2d<span class="o">(</span>256, <span class="nv">eps</span><span class="o">=</span>1e-05, <span class="nv">momentum</span><span class="o">=</span>0.1, <span class="nv">affine</span><span class="o">=</span>True, <span class="nv">track_running_stats</span><span class="o">=</span>True<span class="o">)</span>
  <span class="o">(</span>actv<span class="o">)</span>: ReLU<span class="o">(</span><span class="nv">inplace</span><span class="o">=</span>True<span class="o">)</span>
  <span class="o">(</span>maxpool<span class="o">)</span>: MaxPool2d<span class="o">(</span><span class="nv">kernel_size</span><span class="o">=</span>2, <span class="nv">stride</span><span class="o">=</span>2, <span class="nv">padding</span><span class="o">=</span>0, <span class="nv">dilation</span><span class="o">=</span>1, <span class="nv">ceil_mode</span><span class="o">=</span>False<span class="o">)</span>
  <span class="o">(</span>dropout<span class="o">)</span>: Dropout2d<span class="o">(</span><span class="nv">p</span><span class="o">=</span>0.5, <span class="nv">inplace</span><span class="o">=</span>False<span class="o">)</span>
  <span class="o">(</span>flatten<span class="o">)</span>: Flatten<span class="o">(</span><span class="nv">start_dim</span><span class="o">=</span>1, <span class="nv">end_dim</span><span class="o">=</span><span class="nt">-1</span><span class="o">)</span>
  <span class="o">(</span>fn1<span class="o">)</span>: Linear<span class="o">(</span><span class="nv">in_features</span><span class="o">=</span>12544, <span class="nv">out_features</span><span class="o">=</span>256, <span class="nv">bias</span><span class="o">=</span>True<span class="o">)</span>
  <span class="o">(</span>fn2<span class="o">)</span>: Linear<span class="o">(</span><span class="nv">in_features</span><span class="o">=</span>256, <span class="nv">out_features</span><span class="o">=</span>100, <span class="nv">bias</span><span class="o">=</span>True<span class="o">)</span>
  <span class="o">(</span>fn3<span class="o">)</span>: Linear<span class="o">(</span><span class="nv">in_features</span><span class="o">=</span>100, <span class="nv">out_features</span><span class="o">=</span>10, <span class="nv">bias</span><span class="o">=</span>True<span class="o">)</span>
<span class="o">)</span> 

<span class="o">=====</span> Model Parameters <span class="o">=====</span>
 - 3535446 

Training start <span class="nb">time</span> : 2022-06-01 12:36:36.501451

/Users/bolero/m1_gpu.py:63: UserWarning: Implicit dimension choice <span class="k">for </span>softmax has been deprecated. Change the call to include <span class="nv">dim</span><span class="o">=</span>X as an argument.
  <span class="k">return </span>softmax<span class="o">(</span>x<span class="o">)</span>
<span class="o">[</span>train     1/ 3750] Epoch:    1 | Time:   0.32s | loss:     2.3119 | Acc:     0.1250
<span class="o">[</span>train  1876/ 3750] Epoch:    1 | Time:   0.03s | loss:     1.4933 | Acc:     0.9375
<span class="o">[</span>Epoch 1 training Ended] <span class="o">&gt;</span> Time: 1.3e+02s/epoch | Loss: 1.5247 | Acc: 0.9397
</code></pre></div></div>

<p><strong><em>M1 Macbook Pro - GPU</em></strong></p>

<blockquote>
  <p>🧐 솔직히 M1-CPU 나 M1-GPU 나 뭔가 코딩 잘못했을 줄 알고 기대 안했는데, 의외로 차이가 발생했다.
<strong>M1-CPU가 170초~180초/epoch 정도 나오고, M1-GPU는 130초/epoch 정도 나오는데, M1-CPU 의 수준이 Intel Xeon 4210R 2.40GHz 40 Core 정도의 수준을 보였다.</strong></p>
</blockquote>

<p>결론은… M1-GPU 는 엄청 쓸 정도는 아니다 아직! 그래도 CPU보다는 나으니 간단한 테스팅 정도는 무리없이 돌릴 수 있을 것으로 예상됨.</p>

<p><strong>(단점은, 아까 실험해봤는데 <code class="language-plaintext highlighter-rouge">image_size=[224, 224]</code> 로 하고 <code class="language-plaintext highlighter-rouge">batch_size=64</code> 로 하니까 macbook에 5~7초마다 쓰로틀링이 발생했다…🥲)</strong></p>

<p>학습 종료 때 실험 방식 별 매 Epoch의 소요시간을 저장하는데, 그래프로 그려보는 걸로 포스팅을 마무리 하겠다.
(server CPU는 서버 머신의 다른 작업때문에 20 Epochs까지 측정하지 못함.)</p>

<p><strong>소스코드</strong></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">matplotlib</span> <span class="kn">import</span> <span class="n">pyplot</span> <span class="k">as</span> <span class="n">plt</span>

<span class="n">server_gpu</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">20</span><span class="p">)]</span>
<span class="n">m1_gpu</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">20</span><span class="p">)]</span>
<span class="n">m1_cpu</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">20</span><span class="p">)]</span>

<span class="n">epochs</span> <span class="o">=</span> <span class="p">[</span><span class="n">x</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">21</span><span class="p">)]</span>

<span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="s">"server_gpu.txt"</span><span class="p">,</span> <span class="s">'r'</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
    <span class="n">server_gpu</span> <span class="o">=</span> <span class="n">f</span><span class="p">.</span><span class="n">readlines</span><span class="p">()</span>
    <span class="n">server_gpu</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">map</span><span class="p">(</span><span class="nb">float</span><span class="p">,</span> <span class="n">server_gpu</span><span class="p">))</span>

<span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="s">"m1_gpu.txt"</span><span class="p">,</span> <span class="s">'r'</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
    <span class="n">m1_gpu</span> <span class="o">=</span> <span class="n">f</span><span class="p">.</span><span class="n">readlines</span><span class="p">()</span>
    <span class="n">m1_gpu</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">map</span><span class="p">(</span><span class="nb">float</span><span class="p">,</span> <span class="n">m1_gpu</span><span class="p">))</span>

<span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="s">"m1_cpu.txt"</span><span class="p">,</span> <span class="s">'r'</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
    <span class="n">m1_cpu</span> <span class="o">=</span> <span class="n">f</span><span class="p">.</span><span class="n">readlines</span><span class="p">()</span>
    <span class="n">m1_cpu</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">map</span><span class="p">(</span><span class="nb">float</span><span class="p">,</span> <span class="n">m1_cpu</span><span class="p">))</span>

<span class="n">plt</span><span class="p">.</span><span class="n">figure</span><span class="p">()</span>
<span class="n">plt</span><span class="p">.</span><span class="n">title</span><span class="p">(</span><span class="s">'Training time per devices'</span><span class="p">)</span>

<span class="n">plt</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="n">epochs</span><span class="p">,</span> <span class="n">server_gpu</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="s">'o'</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s">'green'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="n">epochs</span><span class="p">,</span> <span class="n">m1_gpu</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="s">'o'</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s">'red'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="n">epochs</span><span class="p">,</span> <span class="n">m1_cpu</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="s">'o'</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s">'black'</span><span class="p">)</span>

<span class="n">plt</span><span class="p">.</span><span class="n">legend</span><span class="p">([</span><span class="s">'Server GPU'</span><span class="p">,</span> <span class="s">'Server CPU'</span><span class="p">,</span> <span class="s">'M1 GPU'</span><span class="p">,</span> <span class="s">'M1 CPU'</span><span class="p">])</span>
<span class="n">plt</span><span class="p">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s">"Epochs"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s">"Running time(seconds)"</span><span class="p">)</span>
<span class="c1"># plt.show()
</span><span class="n">plt</span><span class="p">.</span><span class="n">savefig</span><span class="p">(</span><span class="s">"runtime.png"</span><span class="p">)</span>
</code></pre></div></div>

<p><strong>결과 이미지</strong><br />
<img src="https://velog.velcdn.com/images/bolero2/post/b04b61e8-e95a-46be-b214-049e490f2955/image.png" alt="" /></p>

:ET